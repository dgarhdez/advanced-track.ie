{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to DuckDB, Polars & Parquet\n",
    "\n",
    "In the previous session we connected to a remote **DB2** database using SQLAlchemy. That works, but every query travels over the network to the server and back. For analytical work — aggregations, joins, window functions — this round-trip overhead adds up quickly.\n",
    "\n",
    "This session introduces three tools that form a modern local-analytics stack:\n",
    "\n",
    "| Tool | What it is | Role in our workflow |\n",
    "|------|-----------|---------------------|\n",
    "| **Parquet** | A columnar file format | Stores our data on disk — compact, fast to read |\n",
    "| **DuckDB** | An embedded analytical database | Runs SQL queries directly on Parquet files |\n",
    "| **Polars** | A fast DataFrame library (alternative to pandas) | DataFrame operations when we want Python, not SQL |\n",
    "\n",
    "### Why not just pandas?\n",
    "\n",
    "| | pandas | Polars |\n",
    "|---|---|---|\n",
    "| **Engine** | Single-threaded, row-oriented | Multi-threaded, columnar (Apache Arrow) |\n",
    "| **Speed on large data** | Slows down on millions of rows | Stays fast — designed for it |\n",
    "| **Memory** | Often copies data | Zero-copy where possible |\n",
    "| **Lazy evaluation** | No — every step executes immediately | Yes — can optimise a chain of operations before running |\n",
    "\n",
    "### Our workflow\n",
    "\n",
    "1. **Download** the tables from DB2 once (using SQLAlchemy)\n",
    "2. **Save** each table as a Parquet file in a `data/` folder\n",
    "3. **Query** locally with DuckDB or Polars — fast, offline, no server needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 — What is Parquet?\n",
    "\n",
    "Parquet is a **columnar** file format, which means data is stored column-by-column instead of row-by-row. This makes analytical queries (\"sum this column\", \"filter by that column\") much faster because the engine only reads the columns it needs.\n",
    "\n",
    "| Format | Structure | File size (typical) | Read speed for analytics |\n",
    "|--------|-----------|--------------------|--------------------------|\n",
    "| **CSV** | Row-based, plain text | Large | Slow — must parse every row and column |\n",
    "| **Parquet** | Columnar, binary, compressed | Small (3–10x smaller than CSV) | Fast — reads only the columns needed |\n",
    "\n",
    "Parquet files are the standard interchange format in modern data work. DuckDB, Polars, pandas, Spark, and most cloud tools all read them natively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 — Download DB2 Tables and Save as Parquet\n",
    "\n",
    "This is a **one-time operation**. We use SQLAlchemy to read each table from DB2, then save it as a Parquet file. After this, you won't need the DB2 connection again.\n",
    "\n",
    "### 2.1 — Connect to DB2 (same as session 00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\nimport polars as pl\nfrom dotenv import load_dotenv\nfrom urllib.parse import quote_plus\nfrom sqlalchemy import create_engine\n\nload_dotenv()\n\nengine = create_engine(\n    f\"db2+ibm_db://{os.getenv('DB_USERNAME')}:{quote_plus(os.getenv('DB_PASSWORD'))}\"\n    f\"@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n)\n\nprint(\"DB2 connection ready.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.2 — Download all tables and save as Parquet\n\nPolars can read directly from a database using `pl.read_database()`. We pass our SQL query and the SQLAlchemy engine — no pandas needed.\n\nFor each table we:\n1. Read it from DB2 directly into a Polars DataFrame with `pl.read_database()`\n2. Write to a `.parquet` file in the `data/` folder\n\n> **Note:** The `TICKETS` table has ~35 million rows. Downloading it will take a few minutes depending on your connection. All other tables are small and finish in seconds."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "DATA_DIR = Path(\"data\")\nDATA_DIR.mkdir(exist_ok=True)\n\ntables = [\n    \"COUNTRIES\",\n    \"DEPARTMENT\",\n    \"EMPLOYEE\",\n    \"AIRPLANES\",\n    \"AIRPORTS\",\n    \"ROUTES\",\n    \"FLIGHTS\",\n    \"PASSENGERS\",\n    \"TICKETS\",\n]\n\nfor table in tables:\n    path = DATA_DIR / f\"{table.lower()}.parquet\"\n    print(f\"Downloading {table}...\", end=\" \", flush=True)\n\n    # Polars reads directly from DB2 via the SQLAlchemy engine\n    df = pl.read_database(f\"SELECT * FROM IEPLANE.{table}\", connection=engine)\n    df.write_parquet(path)\n\n    print(f\"{len(df):>12,} rows  →  {path}\")\n\nprint(\"\\nDone! All tables saved as Parquet files in data/\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 — Verify the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in sorted(DATA_DIR.glob(\"*.parquet\")):\n",
    "    size_mb = path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {path.name:<25} {size_mb:>8.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 — Querying Parquet Files with DuckDB\n",
    "\n",
    "One of DuckDB's killer features: it can query Parquet files **directly** — no loading, no importing. Just point it at the file.\n",
    "\n",
    "### 3.1 — Basic queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Query a Parquet file directly — just use the file path as the table name\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM 'data/airports.parquet'\n",
    "    LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many flights per year?\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        YEAR(departure)  AS year,\n",
    "        COUNT(*)         AS num_flights\n",
    "    FROM 'data/flights.parquet'\n",
    "    GROUP BY year\n",
    "    ORDER BY year\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 airports by number of departing routes\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        a.airport,\n",
    "        a.city,\n",
    "        COUNT(r.route_code) AS num_routes\n",
    "    FROM 'data/airports.parquet' a\n",
    "    JOIN 'data/routes.parquet'   r ON a.iata_code = r.origin\n",
    "    GROUP BY a.airport, a.city\n",
    "    ORDER BY num_routes DESC\n",
    "    LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 — Tip: Create VIEWs to avoid repeating file paths\n",
    "\n",
    "Typing `'data/flights.parquet'` every time gets tedious. You can create **views** that act as aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create views for all our Parquet files\n",
    "for path in sorted(DATA_DIR.glob(\"*.parquet\")):\n",
    "    name = path.stem  # e.g. \"flights\" from \"flights.parquet\"\n",
    "    duckdb.execute(f\"CREATE OR REPLACE VIEW {name} AS SELECT * FROM '{path}'\")\n",
    "\n",
    "# Now we can query by table name\n",
    "duckdb.sql(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much cleaner!\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        a.airport,\n",
    "        a.city,\n",
    "        COUNT(r.route_code) AS num_routes\n",
    "    FROM airports a\n",
    "    JOIN routes   r ON a.iata_code = r.origin\n",
    "    GROUP BY a.airport, a.city\n",
    "    ORDER BY num_routes DESC\n",
    "    LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 — Getting results as a Polars DataFrame\n",
    "\n",
    "Use `.pl()` at the end of a query to get the result as a Polars DataFrame. Use `.df()` if you need pandas instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .pl() returns a Polars DataFrame\n",
    "revenue_by_class = duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        class,\n",
    "        COUNT(*)                     AS num_tickets,\n",
    "        ROUND(SUM(total_amount), 2)  AS total_revenue\n",
    "    FROM tickets\n",
    "    GROUP BY class\n",
    "    ORDER BY total_revenue DESC\n",
    "\"\"\").pl()\n",
    "\n",
    "revenue_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(revenue_by_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 — DuckDB can also query Polars DataFrames directly\n",
    "\n",
    "Just like with pandas, DuckDB can read a Polars DataFrame by its **Python variable name**. This works because both DuckDB and Polars use Apache Arrow under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Polars DataFrame\n",
    "sample = pl.DataFrame({\n",
    "    \"product\": [\"Laptop\", \"Phone\", \"Tablet\", \"Laptop\", \"Phone\"],\n",
    "    \"revenue\": [1200, 800, 450, 1350, 900],\n",
    "})\n",
    "\n",
    "# Query it with DuckDB — just use the variable name\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT product, SUM(revenue) AS total\n",
    "    FROM sample\n",
    "    GROUP BY product\n",
    "    ORDER BY total DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 — Working with Polars\n",
    "\n",
    "Polars is a DataFrame library like pandas, but faster. It reads Parquet files natively.\n",
    "\n",
    "### 4.1 — Reading Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pl.read_parquet(\"data/airports.parquet\")\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .schema shows column names and types\n",
    "airports.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .describe() gives summary statistics — similar to pandas\n",
    "airports.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 — Polars syntax crash course\n",
    "\n",
    "Polars uses **expressions** instead of bracket indexing. The pattern is always:\n",
    "\n",
    "```python\n",
    "df.select(...)     # choose columns\n",
    "df.filter(...)     # filter rows\n",
    "df.group_by(...)   # group and aggregate\n",
    "df.sort(...)       # order rows\n",
    "```\n",
    "\n",
    "Inside these methods, use `pl.col(\"column_name\")` to refer to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pl.read_parquet(\"data/employee.parquet\")\n",
    "\n",
    "# Select specific columns\n",
    "employees.select(\"firstnme\", \"lastname\", \"salary\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows: employees earning more than 30,000\n",
    "employees.filter(\n",
    "    pl.col(\"salary\") > 30_000\n",
    ").select(\"firstnme\", \"lastname\", \"salary\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by + aggregate: average salary by education level\n",
    "employees.group_by(\"edlevel\").agg(\n",
    "    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n",
    "    pl.col(\"salary\").count().alias(\"num_employees\"),\n",
    ").sort(\"avg_salary\", descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 — Polars vs pandas cheat sheet\n",
    "\n",
    "| Operation | pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Select columns | `df[[\"a\", \"b\"]]` | `df.select(\"a\", \"b\")` |\n",
    "| Filter rows | `df[df[\"a\"] > 5]` | `df.filter(pl.col(\"a\") > 5)` |\n",
    "| New column | `df[\"c\"] = df[\"a\"] + 1` | `df.with_columns((pl.col(\"a\") + 1).alias(\"c\"))` |\n",
    "| Group + agg | `df.groupby(\"a\").agg({\"b\": \"sum\"})` | `df.group_by(\"a\").agg(pl.col(\"b\").sum())` |\n",
    "| Sort | `df.sort_values(\"a\")` | `df.sort(\"a\")` |\n",
    "| Read Parquet | `pd.read_parquet(\"f.parquet\")` | `pl.read_parquet(\"f.parquet\")` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5 — When to Use What\n",
    "\n",
    "You now have three tools. Here's when each one shines:\n",
    "\n",
    "| Tool | Best for | Example |\n",
    "|------|----------|--------|\n",
    "| **DuckDB SQL** | Multi-table joins, complex aggregations, exploring data | `SELECT ... FROM flights JOIN routes ...` |\n",
    "| **Polars** | Step-by-step data transformations, feature engineering | `df.filter(...).with_columns(...).group_by(...)` |\n",
    "| **DuckDB → `.pl()`** | SQL query, then continue in Polars | `duckdb.sql(\"...\").pl().with_columns(...)` |\n",
    "\n",
    "They work together seamlessly — use whichever feels more natural for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: a multi-table join in DuckDB\n",
    "\n",
    "\"For each passenger, show their most recent ticket with the flight origin and destination.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        p.firstnme || ' ' || p.lastname  AS passenger,\n",
    "        t.ticket_id,\n",
    "        t.departure,\n",
    "        r.origin,\n",
    "        r.destination,\n",
    "        t.total_amount\n",
    "    FROM tickets t\n",
    "    JOIN passengers p  ON t.passenger_id = p.id\n",
    "    JOIN routes r      ON t.route_code   = r.route_code\n",
    "    ORDER BY t.departure DESC\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 — Using Your Data in Future Sessions\n",
    "\n",
    "Once the Parquet files exist in `data/`, this is all you need at the top of any notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Copy this block into future notebooks ---\n",
    "# import duckdb\n",
    "# import polars as pl\n",
    "# from pathlib import Path\n",
    "#\n",
    "# # Register all Parquet files as DuckDB views\n",
    "# for path in sorted(Path(\"data\").glob(\"*.parquet\")):\n",
    "#     duckdb.execute(f\"CREATE OR REPLACE VIEW {path.stem} AS SELECT * FROM '{path}'\")\n",
    "#\n",
    "# # Now query with SQL:\n",
    "# duckdb.sql(\"SELECT COUNT(*) FROM tickets\")\n",
    "#\n",
    "# # Or read directly into Polars:\n",
    "# flights = pl.read_parquet(\"data/flights.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7 — Useful Commands Reference\n",
    "\n",
    "### DuckDB\n",
    "\n",
    "| Command | What it does |\n",
    "|---------|-------------|\n",
    "| `duckdb.sql(\"SHOW TABLES\")` | List all views/tables |\n",
    "| `duckdb.sql(\"DESCRIBE table\")` | Show columns and types |\n",
    "| `duckdb.sql(\"SUMMARIZE table\")` | Quick statistics for every column |\n",
    "| `.pl()` | Convert result to Polars DataFrame |\n",
    "| `.df()` | Convert result to pandas DataFrame |\n",
    "\n",
    "### Polars\n",
    "\n",
    "| Command | What it does |\n",
    "|---------|-------------|\n",
    "| `df.head()` | First 5 rows |\n",
    "| `df.schema` | Column names and types |\n",
    "| `df.describe()` | Summary statistics |\n",
    "| `df.shape` | (rows, columns) |\n",
    "| `df.null_count()` | Count nulls per column |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARIZE gives a statistical overview — very handy for exploration\n",
    "duckdb.sql(\"SUMMARIZE airports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8 — Practice\n",
    "\n",
    "Try these on your own. Use either DuckDB SQL or Polars — your choice! Solutions are at the bottom.\n",
    "\n",
    "1. How many employees are there per department? Show department name and count, ordered by count descending.\n",
    "2. What are the 5 longest routes by distance? Include origin and destination airport names.\n",
    "3. What is the average ticket price per class (`E`, `P`, `B`)?\n",
    "4. Which country has the most passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Employees per department\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: 5 longest routes with airport names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Average ticket price per class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Country with most passengers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solutions (DuckDB SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT d.deptname, COUNT(*) AS num_employees\n",
    "    FROM employee e\n",
    "    JOIN department d ON e.workdept = d.deptno\n",
    "    GROUP BY d.deptname\n",
    "    ORDER BY num_employees DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        r.route_code,\n",
    "        a1.airport AS origin_airport,\n",
    "        a2.airport AS destination_airport,\n",
    "        r.distance\n",
    "    FROM routes r\n",
    "    JOIN airports a1 ON r.origin      = a1.iata_code\n",
    "    JOIN airports a2 ON r.destination  = a2.iata_code\n",
    "    ORDER BY r.distance DESC\n",
    "    LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        class,\n",
    "        ROUND(AVG(price), 2) AS avg_price\n",
    "    FROM tickets\n",
    "    GROUP BY class\n",
    "    ORDER BY avg_price DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 4\n",
    "duckdb.sql(\"\"\"\n",
    "    SELECT country, COUNT(*) AS num_passengers\n",
    "    FROM passengers\n",
    "    GROUP BY country\n",
    "    ORDER BY num_passengers DESC\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions (Polars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1 — Polars\n",
    "emp = pl.read_parquet(\"data/employee.parquet\")\n",
    "dept = pl.read_parquet(\"data/department.parquet\")\n",
    "\n",
    "emp.join(\n",
    "    dept, left_on=\"workdept\", right_on=\"deptno\"\n",
    ").group_by(\"deptname\").agg(\n",
    "    pl.len().alias(\"num_employees\")\n",
    ").sort(\"num_employees\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3 — Polars\n",
    "tix = pl.read_parquet(\"data/tickets.parquet\")\n",
    "\n",
    "tix.group_by(\"class\").agg(\n",
    "    pl.col(\"price\").mean().round(2).alias(\"avg_price\")\n",
    ").sort(\"avg_price\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 4 — Polars\n",
    "pax = pl.read_parquet(\"data/passengers.parquet\")\n",
    "\n",
    "pax.group_by(\"country\").agg(\n",
    "    pl.len().alias(\"num_passengers\")\n",
    ").sort(\"num_passengers\", descending=True).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}